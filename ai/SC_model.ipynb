{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.models import convnext_small\n",
    "\n",
    "class ClothesClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=False):\n",
    "        super(ClothesClassifier, self).__init__()\n",
    "        freeze_ratio = 0.8\n",
    "        self.model = convnext_small(weights=\"IMAGENET1K_V1\" if pretrained else None)\n",
    "\n",
    "        num_stages = len(self.model.features)\n",
    "        num_stages_to_freeze = int(freeze_ratio * num_stages)\n",
    "\n",
    "        for stage_idx in range(num_stages_to_freeze):\n",
    "            for param in self.model.features[stage_idx].parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        in_features = self.model.classifier[2].in_features\n",
    "        self.model.classifier[2] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def load_model(model_path, num_classes, device=\"cuda\"):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file '{model_path}' not found.\")\n",
    "    model = ClothesClassifier(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess an image for model input.\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, category_mapping, device=\"cuda\"):\n",
    "   \n",
    "    image = preprocess_image(image_path).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "    \n",
    "    predicted_class = torch.argmax(outputs, dim=1).item()\n",
    "    \n",
    "    # Reverse mapping from index to class name\n",
    "    idx_to_category = {v: k for k, v in category_mapping.items()}\n",
    "    predicted_category = idx_to_category.get(predicted_class, \"Unknown\")\n",
    "    \n",
    "    print(f\"Predicted Category: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Bags\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print (f\"Using device: {device}\")\n",
    "# Example usage\n",
    "model_path = \"C:/Users/DELL/Downloads/model_weights_last.pth\"  # Update with your actual path\n",
    "num_classes = 7  # Use the actual number of classes from training\n",
    "image_path = \"C:/Users/DELL/OneDrive/Pictures/Wardrobe/png-transparent-handbag-designer-woman-women-s-handbags-white-luggage-bags-holidays-thumbnail.png\"\n",
    "\n",
    "# Mapping category indices to names (from dataset processing)\n",
    "category_mapping = {'Bags': 0, 'Bottomwear': 1, 'Headwear': 2, 'Jewellery': 3, 'Shoes': 4, 'Topwear': 5, 'Watches': 6}\n",
    "\n",
    "# Load the model with the correct device\n",
    "model = load_model(model_path, num_classes, device=device)\n",
    "\n",
    "# Print the model architecture\n",
    "# Perform prediction\n",
    "predict(image_path, model, category_mapping, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
